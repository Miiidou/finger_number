{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finger_number",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMco1ShUJjnV/dlrxgE0I53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miiidou/finger_number/blob/main/finger_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WSluwpN3zn_",
        "outputId": "01a8cc38-05c8-4a3b-cadd-37ffd28e166a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Training dataset 5 - 25 items\n",
            "Training dataset 1 - 25 items\n",
            "Training dataset 3 - 25 items\n",
            "Training dataset 0 - 25 items\n",
            "Training dataset 4 - 25 items\n",
            "Training dataset 2 - 25 items\n",
            "Validation dataset 5 - 15 items\n",
            "Validation dataset 1 - 3 items\n",
            "Validation dataset 3 - 6 items\n",
            "Validation dataset 0 - 8 items\n",
            "Validation dataset 4 - 8 items\n",
            "Validation dataset 2 - 10 items\n",
            "Found 150 files belonging to 6 classes.\n",
            "Using 120 files for training.\n",
            "Found 50 files belonging to 6 classes.\n",
            "Using 10 files for validation.\n",
            "WARNING:tensorflow:`embeddings_data` is not supported in TensorFlow 2.0. Instead, all `Embedding` variables will be visualized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`embeddings_data` is not supported in TensorFlow 2.0. Instead, all `Embedding` variables will be visualized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 37s 908ms/step - loss: 1.8102 - accuracy: 0.1250 - val_loss: 1.7867 - val_accuracy: 0.3000\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 36s 892ms/step - loss: 1.7945 - accuracy: 0.1417 - val_loss: 1.7944 - val_accuracy: 0.2000\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 36s 899ms/step - loss: 1.7925 - accuracy: 0.1417 - val_loss: 1.7937 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 36s 888ms/step - loss: 1.7921 - accuracy: 0.1833 - val_loss: 1.7935 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 36s 891ms/step - loss: 1.7918 - accuracy: 0.1833 - val_loss: 1.7946 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 37s 904ms/step - loss: 1.8044 - accuracy: 0.2000 - val_loss: 1.7986 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 37s 909ms/step - loss: 1.7964 - accuracy: 0.1833 - val_loss: 1.7936 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 36s 889ms/step - loss: 1.7923 - accuracy: 0.1833 - val_loss: 1.7568 - val_accuracy: 0.3000\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 36s 880ms/step - loss: 1.7919 - accuracy: 0.2333 - val_loss: 1.7242 - val_accuracy: 0.2000\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 36s 877ms/step - loss: 1.8094 - accuracy: 0.2583 - val_loss: 1.7863 - val_accuracy: 0.2000\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 36s 883ms/step - loss: 1.7108 - accuracy: 0.2833 - val_loss: 2.1642 - val_accuracy: 0.3000\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 36s 874ms/step - loss: 1.6900 - accuracy: 0.3167 - val_loss: 2.0495 - val_accuracy: 0.2000\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 36s 891ms/step - loss: 1.5419 - accuracy: 0.4083 - val_loss: 2.5703 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 37s 912ms/step - loss: 1.2910 - accuracy: 0.5500 - val_loss: 3.0733 - val_accuracy: 0.4000\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 37s 906ms/step - loss: 1.0892 - accuracy: 0.5500 - val_loss: 3.5855 - val_accuracy: 0.4000\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 37s 900ms/step - loss: 0.7460 - accuracy: 0.6917 - val_loss: 4.6081 - val_accuracy: 0.4000\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 37s 907ms/step - loss: 0.4150 - accuracy: 0.8583 - val_loss: 7.4655 - val_accuracy: 0.4000\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 36s 893ms/step - loss: 0.2473 - accuracy: 0.9000 - val_loss: 10.3840 - val_accuracy: 0.3000\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 37s 902ms/step - loss: 0.2061 - accuracy: 0.9250 - val_loss: 11.0150 - val_accuracy: 0.3000\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 36s 894ms/step - loss: 0.2112 - accuracy: 0.9417 - val_loss: 10.9303 - val_accuracy: 0.4000\n"
          ]
        }
      ],
      "source": [
        "# Réseau neuronal permettant d'indentifier le chiffre indiqué avec les doigts. \n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import sys\n",
        "import datetime\n",
        "import zipfile\n",
        "import pathlib\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "%pylab inline\n",
        "\n",
        "# Import training dataset\n",
        "data_dir = tf.keras.utils.get_file(\n",
        "    \"dataset.zip\",\n",
        "    \"https://github.com/Miiidou/finger_number/blob/3e1ab0b81896510c835c6a7b7fd3f9400ec80f20/dataset.zip?raw=true\",\n",
        "    extract=False)\n",
        "\n",
        "with zipfile.ZipFile(data_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/datasets')\n",
        "\n",
        "data_dir = pathlib.Path('/content/datasets/dataset')\n",
        "\n",
        "# Import validation dataset\n",
        "validation_dir = tf.keras.utils.get_file(\n",
        "    \"test.zip\",\n",
        "    \"https://github.com/Miiidou/finger_number/blob/35d939e625399f8c11c6406758ed481ad3fdd01b/test.zip?raw=true\",\n",
        "    extract=False)\n",
        "\n",
        "with zipfile.ZipFile(validation_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/datasets')\n",
        "\n",
        "validation_dir = pathlib.Path('/content/datasets/test')\n",
        "\n",
        "# Convert JPG files to PNG\n",
        "from PIL import Image\n",
        "datasetsList = [pathlib.Path(data_dir).glob('*'),pathlib.Path(validation_dir).glob('*')]\n",
        "for idx, dataset in enumerate(datasetsList) :\n",
        "  for data_folder in dataset :\n",
        "    folders = [f for f in listdir(data_folder) if isfile(join(data_folder, f))]\n",
        "    for fichier in folders : \n",
        "      file_name = pathlib.Path(fichier).stem\n",
        "      file_ext = pathlib.Path(fichier).suffix\n",
        "      file_path_jpg = join(data_folder,fichier)\n",
        "      file_path_png = pathlib.Path(str(data_folder) + \"/\" + str(file_name) + \".png\")\n",
        "      if((file_ext == \".jpg\") and (not isfile(file_path_png))) :\n",
        "        im = Image.open(str(file_path_jpg))\n",
        "        im.save(str(file_path_png)) \n",
        "        os.remove(file_path_jpg) \n",
        "      elif(file_ext == \".jpg\") : \n",
        "        os.remove(file_path_jpg) \n",
        "    folders = [f for f in listdir(data_folder) if isfile(join(data_folder, f))]\n",
        "    if(idx == 0) :\n",
        "      print(\"Training dataset \" + str(data_folder.stem) + \" - \" + str(len(folders)) + \" items\")\n",
        "    elif(idx == 1) :\n",
        "      print(\"Validation dataset \" + str(data_folder.stem) + \" - \" + str(len(folders)) + \" items\")\n",
        "\n",
        "# Préprocessing \n",
        "batch_size = 3\n",
        "img_height = 200\n",
        "img_width = 200\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  validation_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "class_names = val_data.class_names\n",
        "# print(class_names)\n",
        "\n",
        "# Neuronal network\n",
        "num_classes = 6\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.Conv2D(128,4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64,4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32,4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(16,4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "logdir=\"logs\"\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1, write_images=logdir,\n",
        "                                                   embeddings_data=train_data)\n",
        "\n",
        "model.fit( \n",
        "  train_data,\n",
        "  validation_data=val_data,\n",
        "  epochs=100,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Enjoying prediction\n",
        "from google.colab import files\n",
        "file_to_predict = files.upload()\n",
        "for file_ in file_to_predict:\n",
        "    image_to_predict = cv2.imread(file_,cv2.IMREAD_COLOR)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(cv2.cvtColor(image_to_predict, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "    img_to_predict = np.expand_dims(cv2.resize(image_to_predict,(200,200)), axis=0) \n",
        "    res = np.argmax(model.predict(img_to_predict), axis=1)\n",
        "    print(model.predict(img_to_predict))\n",
        "    if res == 0:\n",
        "        print(\"IT'S A 0 !\")\n",
        "    elif res == 1 :\n",
        "        print(\"IT'S A 1 !\")\n",
        "    elif res == 2 :\n",
        "        print(\"IT'S A 2 !\")\n",
        "    elif res == 3 :\n",
        "        print(\"IT'S A 3 !\")\n",
        "    elif res == 4 :\n",
        "        print(\"IT'S A 4 !\")\n",
        "    elif res == 5 :\n",
        "        print(\"IT'S A 5 !\")"
      ]
    }
  ]
}